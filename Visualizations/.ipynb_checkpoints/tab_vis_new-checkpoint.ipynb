{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3926e043-6c19-4b7b-89d8-657a2cdcd381",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 579\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# Run the app\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\dash.py:2287\u001b[0m, in \u001b[0;36mDash.run_server\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"`run_server` is a deprecated alias of `run` and may be removed in a\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;124;03mfuture version. We recommend using `app.run` instead.\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \n\u001b[0;32m   2280\u001b[0m \u001b[38;5;124;03mSee `app.run` for usage information.\u001b[39;00m\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2282\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\n\u001b[0;32m   2284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDash.run_server is deprecated and will be removed in Dash 3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m     )\n\u001b[0;32m   2286\u001b[0m )\n\u001b[1;32m-> 2287\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\dash.py:2173\u001b[0m, in \u001b[0;36mDash.run\u001b[1;34m(self, host, port, proxy, debug, jupyter_mode, jupyter_width, jupyter_height, jupyter_server_url, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_prune_errors, **flask_run_options)\u001b[0m\n\u001b[0;32m   2170\u001b[0m             extra_files\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jupyter_dash\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m-> 2173\u001b[0m     \u001b[43mjupyter_dash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_app\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjupyter_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjupyter_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjupyter_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjupyter_server_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun(host\u001b[38;5;241m=\u001b[39mhost, port\u001b[38;5;241m=\u001b[39mport, debug\u001b[38;5;241m=\u001b[39mdebug, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflask_run_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:405\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    403\u001b[0m     display(HTML(msg))\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_error\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:392\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     \u001b[43mwait_for_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_colab:\n\u001b[0;32m    395\u001b[0m         JupyterDash\u001b[38;5;241m.\u001b[39m_display_in_colab(dashboard_url, port, mode, width, height)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop(attempt_number, delay_since_first_attempt_ms):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(attempt)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[1;34m(self, wrap_exception)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m         \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_attempts(attempt_number)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:383\u001b[0m, in \u001b[0;36mJupyterDash.run_app.<locals>.wait_for_app\u001b[1;34m()\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    382\u001b[0m         url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddress \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already in use.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Try passing a different port to run_server.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m         )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    388\u001b[0m     _get_error()\n",
      "\u001b[1;31mOSError\u001b[0m: Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server."
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import time\n",
    "data = {\"Provenance\":{\n",
    "  \"db_repo_structured_db\": {\n",
    "    \"identifier\": \"Globally Unique ID for dataset from the registry (FAIR-DATA, DataCite)Example: DOI (Digital Object Identifier), ORCID (for researchers), UUIDs (Universally Unique Identifiers), and Handles (e.g., Handle.net). for datatset, Zonodo, Datacite f1\",\n",
    "    \"title\": \"Dataset title (FAIR-DATA, DataCite)\",\n",
    "    \"description\": \"Brief description of dataset (FAIR-DATA, Dublin Core)\",\n",
    "    \"keywords\": [\"Relevant search terms (FAIR-DATA)\"],\n",
    "    \"creators\": \"Person or organization that created dataset (PROV-O, DataCite)\",\n",
    "    \"created_date\": \"Date dataset was created (FAIR-DATA, DataCite)\",\n",
    "    \"modified_date\": \"Date of last modification (FAIR-DATA, DataCite)\",\n",
    "    \"provenance\": \"History of dataset, modifications, and ownership (PROV-O)\",\n",
    "    \"access_rights\": \"Who can access the dataset (FAIR-DATA, Dublin Core)a1\",\n",
    "    \"license\": \"Usage license (FAIR-DATA, DataCite)\",\n",
    "    \"source\": \"Original source if derived from another dataset (PROV-O)\",\n",
    "    \"relations\": [\"Links to related datasets (FAIR-DATA, DataCite)\"],\n",
    "    \"storage_location\": \"Physical or digital location of dataset (FAIR-DATA)\",\n",
    "    \"metadata_schema\": \"Schema used for metadata (FAIR-DATA, DataCite)\",\n",
    "    \"format\": \"File format (FAIR-DATA, Dublin Core)\",\n",
    "    \"size\": \"Size of dataset (FAIR-DATA)\",\n",
    "    \"checksum\": \"Integrity check value (FAIR-DATA)\",\n",
    "    \"modification_history\": \"Track dataset changes (PROV-O)\",\n",
    "    \"funding\": \"Funding source (FAIR-DATA)\",\n",
    "    \"contributors\": [\"List of contributors (FAIR-DATA, PROV-O)\"],\n",
    "    \"derived_from\": \"Parent dataset if applicable (PROV-O)\",\n",
    "    \"version\": \"Dataset version (FAIR-DATA, DataCite)\",\n",
    "    \"contact_point\": \"Responsible contact (FAIR-DATA)\",\n",
    "    \"FAIR_compliance_score\": \"Self-evaluation of FAIR principles (FAIR-DATA)\",\n",
    "    \"documentation\": \"Link to dataset documentation (FAIR-DATA)f2\",\n",
    "    \"reference_strategy\":\"FAIR, Datacite, PROVO, DUblincore\",\n",
    "    \"dataset\": {\n",
    "        \"collection_method\": \"How the data was collected (e.g., surveys, sensors, API, manual entry)\",\n",
    "        \"data_structure\": \"Description of dataset structure (e.g., tabular, relational database, hierarchical, graph-based)\",\n",
    "        \"num_records\": \"Total number of records (rows) in the dataset\",\n",
    "        \"num_columns\": \"Total number of features (columns) in the dataset\",\n",
    "        \"column_types\": {\n",
    "            \"categorical\": [\"List of categorical columns\"],\n",
    "            \"numerical\": [\"List of numerical columns\"],\n",
    "            \"text\": [\"List of text-based columns\"],\n",
    "            \"date_time\": [\"List of datetime columns\"],\n",
    "            \"boolean\": [\"List of boolean columns\"]\n",
    "        },\n",
    "        \"summary_statistics\": {\n",
    "            \"numerical\": {\n",
    "                \"mean\": \"Mean of numerical columns\",\n",
    "                \"median\": \"Median of numerical columns\",\n",
    "                \"std_dev\": \"Standard deviation of numerical columns\",\n",
    "                \"min\": \"Minimum values per numerical column\",\n",
    "                \"max\": \"Maximum values per numerical column\"\n",
    "            },\n",
    "            \"categorical\": {\n",
    "                \"unique_values\": \"Unique values per categorical column\",\n",
    "                \"most_frequent\": \"Most common category per categorical column\"\n",
    "            }\n",
    "        },\n",
    "        \"missing_data\": {\n",
    "            \"total_missing_values\": \"Total number of missing values in the dataset\",\n",
    "            \"missing_columns\": [\"List of columns with missing values\"],\n",
    "            \"missing_handling\": \"How missing data was handled (e.g., imputation, removal, left as-is)\"\n",
    "        },\n",
    "        \"outliers\": {\n",
    "            \"columns_with_outliers\": [\"List of columns with detected outliers\"],\n",
    "            \"handling_method\": \"How outliers were treated (e.g., capped, removed, normalized)\"\n",
    "        },\n",
    "        \"sampling_strategy\": \"How data was sampled (e.g., random sampling, stratified sampling)\",\n",
    "        \"data_quality\": \"Assessment of dataset quality, completeness, and validation checks performed\",\n",
    "        \"bias_check\": \"Any known biases in the dataset (e.g., demographic imbalance, selection bias)\",\n",
    "        \"anonymization\": \"If data is anonymized, the techniques used (e.g., k-anonymity, differential privacy)\",\n",
    "        \"geospatial_info\": \"Geographical data details (e.g., GPS coordinates, country codes)\",\n",
    "        \"temporal_coverage\": \"Time period covered by the dataset (e.g., 2015-2023)\",\n",
    "        \"usage_guidelines\": \"Best practices for using this dataset, recommended tools for analysis\",\n",
    "        \"known_issues\": \"Any known limitations, biases, or missing values in the dataset\",\n",
    "        \"citations\": \"References to papers, projects, or research that have used this dataset\",\n",
    "        \"ethics_approval\": \"If the dataset involves human data, details on IRB/ethics board approval\"\n",
    "    }\n",
    "  },\n",
    "  \"unstructured_repository_short\": {\n",
    "    \"identifier\": \"Unique ID for dataset (FAIR-DATA)\",\n",
    "    \"title\": \"Dataset title (FAIR-DATA, Dublin Core)\",\n",
    "    \"description\": \"Brief description (FAIR-DATA, Dublin Core)\",\n",
    "    \"keywords\": [\"Relevant search terms (FAIR-DATA)\"],\n",
    "    \"creator\": \"Person/organization that created dataset (PROV-O, DataCite)\",\n",
    "    \"created_date\": \"Creation date (FAIR-DATA)\",\n",
    "    \"modified_date\": \"Last modification date (FAIR-DATA)\",\n",
    "    \"provenance\": \"History of dataset, modifications, ownership (PROV-O)\",\n",
    "    \"access_rights\": \"Access permissions (FAIR-DATA, Dublin Core)\",\n",
    "    \"license\": \"Usage license (FAIR-DATA, DataCite)\",\n",
    "    \"source\": \"Original source (PROV-O)\",\n",
    "    \"relations\": [\"Links to related datasets (FAIR-DATA, DataCite)\"],\n",
    "    \"storage_location\": \"Physical/digital location (FAIR-DATA)\",\n",
    "    \"format\": \"File format (FAIR-DATA, Dublin Core)\",\n",
    "    \"size\": \"Size of dataset (FAIR-DATA)\",\n",
    "    \"modification_history\": \"Track changes (PROV-O)\",\n",
    "    \"derived_from\": \"Parent dataset if applicable (PROV-O)\",\n",
    "    \"FAIR_compliance_score\": \"Self-evaluation of FAIR principles (FAIR-DATA)\",\n",
    "    \"documentation\": \"Link to dataset documentation (FAIR-DATA)\"\n",
    "  },\n",
    "  \"unstructured_repository\": {\n",
    "    \"identifier\": \"Unique ID for stored artifact (UUID, DOI, Handle) (FAIR-DATA, DataCite, PROV-O)\",\n",
    "    \"title\": \"Title of stored artifact (e.g., model name, log file title) (FAIR-DATA, Dublin Core)\",\n",
    "    \"description\": \"Brief description of the stored artifact (FAIR-DATA, Dublin Core)\",\n",
    "    \"keywords\": [\"Relevant search terms (FAIR-DATA)\"],\n",
    "    \"creator\": {\n",
    "        \"name\": \"Person/organization that created the artifact\",\n",
    "        \"role\": \"Role (e.g., Data Scientist, ML Engineer, System Log Manager) (PROV-O)\",\n",
    "        \"affiliation\": \"Institution or company (FAIR-DATA)\"\n",
    "    },\n",
    "    \"created_date\": \"Date when artifact was created (FAIR-DATA, PROV-O)\",\n",
    "    \"modified_date\": \"Last modification date (FAIR-DATA, PROV-O)\",\n",
    "    \"artifact_type\": \"Type of stored file (e.g., ML model, log file, dataset snapshot, documentation) (FAIR-DATA)\",\n",
    "    \"licesnses\": \"Type of licesnses\",\n",
    "    \"publish\": {\n",
    "    \"published_by\":\"person or org who published\",\n",
    "    \"published_date\":\"person or org who published\",\n",
    "    },\n",
    "    \"provenance\": {\n",
    "        \"generated_by\": \"Process that created this artifact (e.g., ML training pipeline, system logging) (PROV-O)\",\n",
    "        \"version\": \"Artifact version identifier (e.g., v1.0, v2.3) (FAIR-DATA, DataCite)\",\n",
    "        \"lineage\": \"List of related artifacts that influenced this (e.g., previous model version, training dataset) (PROV-O)\"\n",
    "    },\n",
    "    \"access_rights\": \"Who can access this artifact (Public, Restricted, Private) (FAIR-DATA, Dublin Core)\",\n",
    "    \"license\": \"Usage license (e.g., MIT, Apache 2.0, Creative Commons) (FAIR-DATA, DataCite)\",\n",
    "    \"source\": \"If derived, original source or upstream reference (PROV-O, DataCite)\",\n",
    "    \"relations\": [\"Links to related artifacts (e.g., models trained on same dataset, log files for this model) (FAIR-DATA, DataCite)\"],\n",
    "    \"storage_location\": {\n",
    "        \"primary\": \"Path where the artifact is stored (e.g., S3 bucket, Invenio repository, institutional storage) (FAIR-DATA)\",\n",
    "        \"backup\": \"Backup location if applicable\",\n",
    "        \"checksum\": \"SHA-256 or MD5 checksum to ensure data integrity (FAIR-DATA)\"\n",
    "    },\n",
    "    \"format\": \"File format (e.g., .h5, .onnx, .json, .log, .txt) (FAIR-DATA, Dublin Core)\",\n",
    "    \"size\": \"File size in MB, GB (FAIR-DATA)\",\n",
    "    \"modification_history\": [\n",
    "        {\n",
    "            \"modified_date\": \"Timestamp of modification\",\n",
    "            \"modified_by\": \"Person/system modifying it\",\n",
    "            \"change_summary\": \"Description of what was modified\"\n",
    "        }\n",
    "    ],\n",
    "    \"derived_from\": \"Reference to parent artifact (e.g., previous model version, dataset) (PROV-O)\",\n",
    "    \"FAIR_compliance_score\": \"Self-assessed compliance with FAIR principles (FAIR-DATA)\",\n",
    "    \"documentation\": \"Link to documentation (e.g., README, API reference) (FAIR-DATA)\",\n",
    "    \"retention_policy\": {\n",
    "        \"retention_period\": \"How long this artifact will be stored (e.g., 5 years, indefinitely)\",\n",
    "        \"archival_status\": \"Whether the file is archived or active\"\n",
    "    },\n",
    "    \"audit_log\": [\n",
    "        {\n",
    "            \"action\": \"Created/Modified/Reviewed\",\n",
    "            \"timestamp\": \"YYYY-MM-DDTHH:MM:SSZ\",\n",
    "            \"performed_by\": \"User/System that made the change\"\n",
    "        }\n",
    "    ]\n",
    "},\n",
    "\n",
    "  \"machine_learning_metadata\": {\n",
    "    \"experiment_id\": \"Unique ID for experiment (FAIR-ML, MLflow, PROV-O)\",\n",
    "    \"model_name\": \"Name of the trained model (FAIR-ML, MLflow)\",\n",
    "    \"algorithm\": \"Algorithm used (e.g., Random Forest, CNN, LSTM) (FAIR-ML)\",\n",
    "    \"dataset_used\": \"Reference to dataset ID or DOI (FAIR-ML, PROV-O, DataCite)\",\n",
    "    \"training_date\": \"Date when the model was trained in YYYY-MM-DD format (FAIR-ML)\",\n",
    "    \"trained_by\": \"Person/organization responsible for training (PROV-O)\",\n",
    "    \"data_preprocessing\": {\n",
    "        \"missing_values\": {\n",
    "            \"strategy\": \"How missing data was handled (e.g., imputation, removal, mean/median fill, interpolation)\",\n",
    "            \"affected_columns\": [\"List of columns with missing values\"],\n",
    "            \"imputation_method\": \"If imputation was used, specify technique (e.g., KNN, mean, regression)\"\n",
    "        },\n",
    "        \"feature_scaling\": {\n",
    "            \"scaling_method\": \"Scaling method applied (e.g., MinMax, Standardization, Robust Scaling)\",\n",
    "            \"applied_columns\": [\"List of columns where scaling was applied\"]\n",
    "        },\n",
    "        \"encoding\": {\n",
    "            \"categorical_encoding\": \"Method used (e.g., One-Hot Encoding, Label Encoding, Embedding Layers)\",\n",
    "            \"affected_columns\": [\"List of categorical columns transformed\"]\n",
    "        },\n",
    "        \"outlier_handling\": {\n",
    "            \"strategy\": \"How outliers were handled (e.g., winsorization, removal, log transformation)\",\n",
    "            \"affected_columns\": [\"List of columns where outliers were detected\"],\n",
    "            \"detection_method\": \"Method used for outlier detection (e.g., Z-score, IQR, DBSCAN)\"\n",
    "        },\n",
    "        \"data_transformation\": {\n",
    "            \"applied_methods\": [\"Log transformation\", \"Polynomial features\", \"PCA\"],\n",
    "            \"reason_for_transformation\": \"Purpose (e.g., reducing dimensionality, normalizing skewed data)\"\n",
    "        },\n",
    "        \"data_splits\": {\n",
    "            \"train_test_split\": \"Percentage split between training and test sets (e.g., 80-20, 70-30)\",\n",
    "            \"cross_validation_folds\": \"Number of folds used in cross-validation (e.g., k=5)\"\n",
    "        }\n",
    "    },\n",
    "    \"hyperparameters\": {\n",
    "        \"learning_rate\": 0.0,\n",
    "        \"batch_size\": 0,\n",
    "        \"epochs\": 0,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_function\": \"Cross-entropy\"\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"accuracy\": 0.0,\n",
    "        \"f1_score\": 0.0,\n",
    "        \"precision\": 0.0,\n",
    "        \"recall\": 0.0,\n",
    "        \"auc_roc\": 0.0,\n",
    "        \"loss\":  0.0\n",
    "    },\n",
    "    \"model_explainability\": {\n",
    "        \"explainability_report\": \"SHAP, LIME, Attention Weights report (FAIR-ML)\",\n",
    "        \"feature_importance\": [\"List of most important features impacting model predictions\"],\n",
    "        \"explainability_score\": \"Quantitative score measuring model transparency (FAIR-ML)\"\n",
    "    },\n",
    "    \"dependencies\": [\"List of required libraries, e.g., TensorFlow, Scikit-Learn, PyTorch (FAIR-ML, MLflow)\"],\n",
    "    \"environment\": \"Details of software/hardware used, including GPU, CPU, RAM, OS (FAIR-ML, MLflow)\",\n",
    "    \"model_artifact_location\": \"Storage path of trained model (FAIR-ML, MLflow)\",\n",
    "    \"license\": \"License under which the model can be used (e.g., MIT, Apache 2.0) (FAIR-ML, DataCite)\",\n",
    "    \"source_code\": \"GitHub/Bitbucket link to model training and inference scripts (FAIR-ML, PROV-O)\",\n",
    "    \"training_logs\": \"Logs generated during training, including time per epoch and loss trends (FAIR-ML, MLflow)\",\n",
    "    \"previous_model\": \"If model is an updated version, reference to prior model (PROV-O)\",\n",
    "    \"next_model\": \"Future versions of the model, if applicable (PROV-O)\",\n",
    "    \"derived_from\": \"Reference to original dataset or prior models (PROV-O, FAIR-ML)\",\n",
    "    \"model_card\": \"Standardized documentation of model details (FAIR-ML, MLflow)\",\n",
    "    \"validation_results\": {\n",
    "        \"dataset_id\": \"ID/DOI of validation dataset\",\n",
    "        \"validation_metrics\": {\n",
    "            \"accuracy\": 0.0,\n",
    "            \"f1_score\": 0.0,\n",
    "            \"precision\": 0.0,\n",
    "            \"recall\": 0.0\n",
    "        }\n",
    "    },\n",
    "    \"deployment_status\": \"Model deployment details (e.g., production, staging, inactive) (FAIR-ML)\",\n",
    "    \"deployment_endpoint\": \"URL or API endpoint for deployed model\",\n",
    "    \"reproducibility_guidelines\": \"Detailed steps for re-running experiment and training pipeline (FAIR-ML)\",\n",
    "    \"bias_analysis\": {\n",
    "        \"bias_check_method\": \"Techniques used for bias detection (e.g., disparate impact, equalized odds)\",\n",
    "        \"identified_bias\": \"Summary of detected biases in dataset or model predictions\",\n",
    "        \"mitigation_strategies\": \"Steps taken to reduce bias (e.g., reweighting, adversarial debiasing)\"\n",
    "    }\n",
    "}\n",
    ",\n",
    "  \"github_repository_metadata_short_version\": {\n",
    "    \"repo_id\": \"Unique identifier (FAIR-DATA, GitHub API)\",\n",
    "    \"repo_name\": \"Name of repository (GitHub API)\",\n",
    "    \"owner\": \"Repository owner (GitHub API)\",\n",
    "    \"created_date\": \"Date repo was created (FAIR-DATA, GitHub API)\",\n",
    "    \"modified_date\": \"Last update date (FAIR-DATA, GitHub API)\",\n",
    "    \"contributors\": [\"List of contributors (FAIR-DATA, GitHub API)\"],\n",
    "    \"license\": \"Repository license (FAIR-DATA, GitHub API)\",\n",
    "    \"visibility\": \"Public/private (GitHub API)\",\n",
    "    \"source_code\": \"Main source code URL (FAIR-DATA, GitHub API)\",\n",
    "    \"dependencies\": [\"List of dependencies (FAIR-DATA, GitHub API)\"],\n",
    "    \"commits\": \"Number of commits (GitHub API)\",\n",
    "    \"pull_requests\": \"Number of PRs merged (GitHub API)\",\n",
    "    \"workflow_runs\": \"List of automated CI/CD runs (GitHub API)\",\n",
    "    \"issues\": \"Open/closed issues (GitHub API)\",\n",
    "    \"forks\": \"Number of forks (GitHub API)\",\n",
    "    \"stars\": \"Number of stars (GitHub API)\",\n",
    "    \"watchers\": \"Number of watchers (GitHub API)\",\n",
    "    \"readme\": \"Link to README (FAIR-DATA, GitHub API)\",\n",
    "    \"releases\": \"List of releases (GitHub API)\",\n",
    "    \"security_scans\": \"Vulnerability scans (GitHub API)\",\n",
    "    \"modification_history\": \"Track changes (PROV-O)\",\n",
    "    \"derived_from\": \"If repo is forked from another (PROV-O)\",\n",
    "    \"reproducibility_guidelines\": \"Steps for reproducing results (FAIR-ML)\"\n",
    "  },\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \"github_repository_metadata_longer_version\": {\n",
    "    \"repo_id\": \"Unique identifier assigned by GitHub API (FAIR-DATA, GitHub API)\",\n",
    "    \"repo_name\": \"Name of the repository (GitHub API)\",\n",
    "    \"owner\": {\n",
    "        \"username\": \"Owner's GitHub username\",\n",
    "        \"profile_url\": \"URL to GitHub profile\"\n",
    "    },\n",
    "    \"created_date\": \"Date repository was created (YYYY-MM-DD) (FAIR-DATA, GitHub API)\",\n",
    "    \"modified_date\": \"Last update timestamp (YYYY-MM-DD) (FAIR-DATA, GitHub API)\",\n",
    "    \"primary_language\": \"Main programming language used (GitHub API)\",\n",
    "    \"topics\": [\"List of GitHub topics/tags associated with repo (GitHub API)\"],\n",
    "    \"description\": \"Short description of repository (GitHub API, FAIR-DATA)\",\n",
    "    \"contributors\": [\n",
    "        {\n",
    "            \"username\": \"GitHub username\",\n",
    "            \"profile_url\": \"GitHub profile link\",\n",
    "            \"contributions\": \"Number of contributions\"\n",
    "        }\n",
    "    ],\n",
    "    \"license\": {\n",
    "        \"license_name\": \"Repository license (e.g., MIT, Apache 2.0, GPL)\",\n",
    "        \"license_url\": \"URL to license file\"\n",
    "    },\n",
    "    \"visibility\": \"Whether repository is Public/Private (GitHub API)\",\n",
    "    \"fork_status\": {\n",
    "        \"is_forked\": \"Boolean value indicating if repo is a fork\",\n",
    "        \"original_repo\": \"URL of original repository if forked\"\n",
    "    },\n",
    "    \"source_code\": {\n",
    "        \"repo_url\": \"Main repository URL\",\n",
    "        \"default_branch\": \"Default branch name (e.g., main, master)\"\n",
    "    },\n",
    "    \"dependencies\": [\"List of dependencies extracted from package managers (e.g., requirements.txt, package.json, Pipfile)\"],\n",
    "    \"commits\": {\n",
    "        \"total_commits\": \"Number of commits in the repository\",\n",
    "        \"latest_commit_hash\": \"SHA hash of the latest commit\",\n",
    "        \"latest_commit_timestamp\": \"Date of latest commit (YYYY-MM-DD)\",\n",
    "        \"commit_authors\": [\"List of authors who have committed\"]\n",
    "    },\n",
    "    \"pull_requests\": {\n",
    "        \"total_prs\": \"Number of pull requests created\",\n",
    "        \"merged_prs\": \"Number of PRs merged\",\n",
    "        \"open_prs\": \"Number of open PRs\",\n",
    "        \"closed_prs\": \"Number of closed PRs\"\n",
    "    },\n",
    "    \"workflow_runs\": {\n",
    "        \"ci_cd_provider\": \"CI/CD tool used (e.g., GitHub Actions, Travis CI, Jenkins)\",\n",
    "        \"total_runs\": \"Number of workflow runs\",\n",
    "        \"last_run_status\": \"Success/Failure/Cancelled\",\n",
    "        \"last_run_timestamp\": \"Timestamp of last CI/CD execution\"\n",
    "    },\n",
    "    \"issues\": {\n",
    "        \"total_issues\": \"Total number of issues created\",\n",
    "        \"open_issues\": \"Number of open issues\",\n",
    "        \"closed_issues\": \"Number of closed issues\"\n",
    "    },\n",
    "    \"discussion_threads\": {\n",
    "        \"total_discussions\": \"Total number of discussions in GitHub Discussions\",\n",
    "        \"open_discussions\": \"Number of open discussions\",\n",
    "        \"resolved_discussions\": \"Number of resolved discussions\"\n",
    "    },\n",
    "    \"forks\": \"Total number of forks (GitHub API)\",\n",
    "    \"stars\": \"Total number of stars (GitHub API)\",\n",
    "    \"watchers\": \"Total number of watchers (GitHub API)\",\n",
    "    \"readme\": {\n",
    "        \"readme_url\": \"Link to README file\",\n",
    "        \"readme_last_updated\": \"Timestamp of last update to README\"\n",
    "    },\n",
    "    \"code_quality\": {\n",
    "        \"linting_status\": \"Results from code linting tools (e.g., Flake8, ESLint, Pylint)\",\n",
    "        \"test_coverage\": \"Percentage of test coverage from CI/CD pipeline\",\n",
    "        \"static_analysis_tools\": [\"List of tools used (e.g., SonarQube, Bandit, CodeQL)\"]\n",
    "    },\n",
    "    \"security_scans\": {\n",
    "        \"vulnerability_scan_results\": \"Summary of security scan (e.g., GitHub Dependabot alerts)\",\n",
    "        \"critical_vulnerabilities\": \"Number of critical security vulnerabilities\",\n",
    "        \"high_vulnerabilities\": \"Number of high severity security vulnerabilities\",\n",
    "        \"medium_vulnerabilities\": \"Number of medium severity security vulnerabilities\"\n",
    "    },\n",
    "    \"documentation\": {\n",
    "        \"docs_url\": \"Link to additional documentation or Wiki\",\n",
    "        \"doc_coverage\": \"Estimated documentation completeness percentage\",\n",
    "        \"api_documentation\": \"Link to API reference, if applicable\"\n",
    "    },\n",
    "    \"releases\": {\n",
    "        \"latest_release_version\": \"Version number of latest release\",\n",
    "        \"latest_release_date\": \"Date of latest release\",\n",
    "        \"release_notes_url\": \"Link to latest release notes\"\n",
    "    },\n",
    "    \"modification_history\": {\n",
    "        \"change_log_url\": \"Link to CHANGELOG file\",\n",
    "        \"release_history\": [\"List of previous versions and their changes\"]\n",
    "    },\n",
    "    \"derived_from\": \"If repository is derived from another project, link to original repo (PROV-O)\",\n",
    "    \"reproducibility_guidelines\": {\n",
    "        \"setup_steps\": \"Instructions for setting up the repository locally\",\n",
    "        \"dataset_references\": [\"Links to datasets used in the repository\"],\n",
    "        \"hardware_requirements\": \"Minimum hardware needed for running the code\",\n",
    "        \"docker_setup\": \"Dockerfile or docker-compose configuration, if available\",\n",
    "        \"virtual_environment\": \"Virtual environment setup (e.g., Conda, venv, Poetry)\"\n",
    "    },\n",
    "    \"collaboration_tools\": {\n",
    "        \"discussion_enabled\": \"Whether GitHub Discussions is enabled\",\n",
    "        \"projects_enabled\": \"Whether GitHub Projects is used for issue tracking\",\n",
    "        \"wiki_enabled\": \"Whether the repository has a GitHub Wiki\"\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"file_metadata\": {\n",
    "    \"file_id\": \"Unique identifier for this metadata file (UUID, DOI)\",\n",
    "    \"file_name\": \"Name of the metadata file (e.g., dataset_metadata.json)\",\n",
    "    \"file_version\": \"Version of this metadata file (e.g., v1.0, v2.1)\",\n",
    "    \"generated_by\": {\n",
    "        \"name\": \"Full name of person/system generating the file\",\n",
    "        \"organization\": \"Affiliated institution or company\",\n",
    "        \"role\": \"Role of the person (e.g., Data Engineer, Researcher, ML Engineer)\",\n",
    "        \"contact_email\": \"Email of the responsible person\"\n",
    "    },\n",
    "    \"generated_on\": \"Date and time file was created (ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ)\",\n",
    "    \"last_modified\": \"Timestamp of last modification\",\n",
    "    \"authorization\": {\n",
    "        \"approved_by\": \"Name of person or system that authorized this metadata\",\n",
    "        \"approval_date\": \"Date of approval (YYYY-MM-DD)\",\n",
    "        \"approval_status\": \"Approval status (e.g., Pending, Approved, Rejected)\",\n",
    "        \"access_control\": \"Who can modify this file (e.g., Admins, Specific Users, Open Access)\"\n",
    "    },\n",
    "    \"storage\": {\n",
    "        \"storage_location\": \"File storage path (e.g., local path, cloud URL, database ID)\",\n",
    "        \"storage_type\": \"Type of storage (e.g., AWS S3, GitHub, Institutional Server)\",\n",
    "        \"backup_location\": \"Backup path or replication details\",\n",
    "        \"encryption_status\": \"Whether the file is encrypted (True/False)\",\n",
    "        \"checksum\": \"SHA-256 or MD5 checksum for integrity verification\"\n",
    "    },\n",
    "    \"audit_trail\": [\n",
    "        {\n",
    "            \"action\": \"Created/Modified/Reviewed\",\n",
    "            \"timestamp\": \"Date and time of action\",\n",
    "            \"performed_by\": \"Who performed the action\"\n",
    "        }\n",
    "    ],\n",
    "    \"retention_policy\": {\n",
    "        \"retention_period\": \"How long this file will be stored (e.g., 5 years, indefinitely)\",\n",
    "        \"deletion_date\": \"Planned deletion date, if applicable\",\n",
    "        \"archival_status\": \"Whether the file is archived or active\"\n",
    "    },\n",
    "    \"compliance\": {\n",
    "        \"FAIR_compliance\": \"FAIR assessment score (if applicable)\",\n",
    "        \"GDPR_status\": \"Whether the data follows GDPR compliance (True/False)\",\n",
    "        \"data_ethics_review\": \"Ethics board approval if required\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "},\n",
    "\"file_metadata_short\": {\n",
    "    \"file_id\": \"UUID or DOI of this metadata file\",\n",
    "    \"file_name\": \"dataset_metadata.json\",\n",
    "    \"file_version\": \"v1.0\",\n",
    "    \"generated_by\": {\n",
    "        \"name\": \"Creatorâ€™s Name\",\n",
    "        \"organization\": \"Institution/Company\",\n",
    "        \"role\": \"Researcher/Data Engineer\",\n",
    "        \"contact_email\": \"email@example.com\"\n",
    "    },\n",
    "    \"generated_on\": \"YYYY-MM-DDTHH:MM:SSZ\",\n",
    "    \"last_modified\": \"YYYY-MM-DDTHH:MM:SSZ\",\n",
    "    \"authorization\": {\n",
    "        \"approved_by\": \"Approverâ€™s Name\",\n",
    "        \"approval_date\": \"YYYY-MM-DD\",\n",
    "        \"status\": \"Approved/Pending\"\n",
    "    },\n",
    "    \"storage\": {\n",
    "        \"location\": \"Cloud URL / Local Path\",\n",
    "        \"type\": \"AWS S3 / GitHub / Institutional Server\",\n",
    "        \"backup\": \"Backup location\",\n",
    "        \"checksum\": \"SHA-256 hash\"\n",
    "    },\n",
    "    \"audit_trail\": [\n",
    "        {\"action\": \"Created/Modified\", \"timestamp\": \"YYYY-MM-DDTHH:MM:SSZ\", \"by\": \"User Name\"}\n",
    "    ],\n",
    "    \"retention_policy\": {\n",
    "        \"duration\": \"5 years / Indefinite\",\n",
    "        \"deletion_date\": \"YYYY-MM-DD\"\n",
    "    },\n",
    "    \"compliance\": {\n",
    "        \"FAIR_score\": \"Assessment score\",\n",
    "        \"GDPR_status\": \"Compliant/Not Compliant\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "},\n",
    "\n",
    "\"Statistics\": {\n",
    "        \"summary_statistics\": {\n",
    "            \"numerical\": {\n",
    "                \"mean\": 50,\n",
    "                \"median\": 45\n",
    "            },\n",
    "            \"categorical\": {\n",
    "                \"status\": \"active\",\n",
    "                \"category\": \"research\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"Model Visualizations\": {\n",
    "        \"model_accuracy\": 0.85,\n",
    "        \"roc_curve\": \"/roc.png\"  # Ensure this is a valid path to an image\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Get main nodes\n",
    "nodes = list(data.keys())\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Create a sample plot for the visualization part\n",
    "fig = px.bar(\n",
    "    x=[\"Mean\", \"Median\"],\n",
    "    y=[50, 45],\n",
    "    labels={\"x\": \"Stat\", \"y\": \"Value\"},\n",
    "    title=\"Sample Dataset Statistics\"\n",
    ")\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    # Header\n",
    "    html.Header(\n",
    "        html.H1(\"Interactive Provenance Data Viewer\", style={\"textAlign\": \"center\", \"color\": \"#333\", \"marginBottom\": \"20px\"})\n",
    "    ),\n",
    "    \n",
    "    # Tabs with icon\n",
    "    dcc.Tabs(\n",
    "        id=\"tabs\",\n",
    "        value=nodes[0] if nodes else None,\n",
    "        children=[\n",
    "            dcc.Tab(\n",
    "                label=f\"ðŸ“‚ {node}\",\n",
    "                value=node,\n",
    "                style={\"fontSize\": \"24px\", \"fontWeight\": \"bold\", \"padding\": \"10px\", \"color\": \"#0074D9\"}\n",
    "            ) for node in nodes\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    # Content Section\n",
    "    html.Div(id=\"content\", style={\"padding\": \"20px\", \"backgroundColor\": \"#f7f7f7\", \"borderRadius\": \"8px\", \"boxShadow\": \"0 2px 5px rgba(0,0,0,0.1)\"}),\n",
    "    \n",
    "    # Loading Spinner\n",
    "    dcc.Loading(\n",
    "        id=\"loading-spinner\",\n",
    "        type=\"circle\",\n",
    "        children=html.Div(id=\"loading-content\", style={\"textAlign\": \"center\", \"padding\": \"20px\"})\n",
    "    )\n",
    "])\n",
    "\n",
    "# Function to create collapsible nested data\n",
    "def render_nested_node(parent_key, node_data, level=0):\n",
    "    \"\"\"Recursively renders nested nodes as collapsible sections\"\"\"\n",
    "    if isinstance(node_data, dict):\n",
    "        return html.Div([\n",
    "            html.Details([\n",
    "                html.Summary(\n",
    "                    html.B(parent_key), \n",
    "                    style={\"cursor\": \"pointer\", \"marginLeft\": f\"{level * 20}px\", \"padding\": \"5px\", \"backgroundColor\": \"#e0f7fa\", \"borderRadius\": \"4px\", \"border\": \"1px solid #0074D9\"}\n",
    "                ),\n",
    "                html.Ul([html.Li(render_nested_node(k, v, level + 1)) for k, v in node_data.items()])\n",
    "            ])\n",
    "        ])\n",
    "    elif isinstance(node_data, list):\n",
    "        return html.Ul([html.Li(render_nested_node(\"\", v, level)) for v in node_data])\n",
    "    return html.Span(f\"{parent_key}: {str(node_data)}\", style={\"marginLeft\": f\"{level * 20}px\"})\n",
    "\n",
    "# Callback to update content based on tab selection\n",
    "@app.callback(\n",
    "    Output(\"content\", \"children\"),\n",
    "    Output(\"loading-content\", \"children\"),\n",
    "    Input(\"tabs\", \"value\")\n",
    ")\n",
    "def display_content(selected_node):\n",
    "    # Simulate loading content\n",
    "    time.sleep(1)  # Simulating content load time\n",
    "    loading_content = \"Loading content...\"\n",
    "\n",
    "    if not selected_node:\n",
    "        return \"No data available.\", loading_content\n",
    "    \n",
    "    node_data = data[selected_node]\n",
    "    content = html.Div([\n",
    "        html.H3(selected_node, style={\"textDecoration\": \"underline\", \"color\": \"#333\", \"marginBottom\": \"20px\"}),\n",
    "        render_nested_node(selected_node, node_data),\n",
    "        html.Div([\n",
    "            dcc.Graph(\n",
    "                id=\"stat-graph\",\n",
    "                figure=fig,\n",
    "                style={\"marginTop\": \"30px\"}\n",
    "            ),\n",
    "            html.P(\"Interactive visualization of dataset statistics.\", style={\"fontSize\": \"14px\", \"color\": \"#555\"})\n",
    "        ], style={\"backgroundColor\": \"#ffffff\", \"padding\": \"10px\", \"borderRadius\": \"6px\", \"boxShadow\": \"0 2px 5px rgba(0,0,0,0.1)\"})\n",
    "    ])\n",
    "    \n",
    "    return content, \"\"\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True,port=8051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3b2c1f-91e7-4e16-a8f1-aa84ee30d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash\n",
      "  Using cached dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting Flask<3.1,>=1.0.4 (from dash)\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Werkzeug<3.1 (from dash)\n",
      "  Using cached werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from dash) (6.0.0)\n",
      "Collecting dash-html-components==2.0.0 (from dash)\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash)\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash)\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\reema\\anaconda3\\lib\\site-packages (from dash) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from dash) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\reema\\anaconda3\\lib\\site-packages (from dash) (2.31.0)\n",
      "Collecting retrying (from dash)\n",
      "  Using cached retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\reema\\appdata\\roaming\\python\\python311\\site-packages (from dash) (1.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\reema\\anaconda3\\lib\\site-packages (from dash) (68.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (1.30.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\reema\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (23.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from Werkzeug<3.1->dash) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from requests->dash) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from requests->dash) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from requests->dash) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from requests->dash) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\reema\\anaconda3\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\reema\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.3->Flask<3.1,>=1.0.4->dash) (0.4.6)\n",
      "Using cached dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
      "Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Using cached retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, Flask, dash\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.1.3\n",
      "    Uninstalling Werkzeug-3.1.3:\n",
      "      Successfully uninstalled Werkzeug-3.1.3\n",
      "  Attempting uninstall: Flask\n",
      "    Found existing installation: Flask 3.1.0\n",
      "    Uninstalling Flask-3.1.0:\n",
      "      Successfully uninstalled Flask-3.1.0\n",
      "Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e10c2c-e9fb-47e7-ab9d-d6ef773e0b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
